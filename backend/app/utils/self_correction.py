"""
Self-Correction Framework for PartnerForge

Analyzes test failures and suggests/applies corrections automatically.
Part of the test-alongside development methodology.

Key Components:
- FixAction: Classification of how to handle a failure
- FailureAnalysis: Detailed analysis with fix suggestions
- SelfCorrector: Main analyzer that processes failures
- ValidationResult: Standard result format from tests

Usage:
    corrector = SelfCorrector()

    # Analyze a failure
    analysis = corrector.analyze_failure(test_result)

    # Apply auto-fix if safe
    if corrector.apply_fix(analysis):
        print("Fix applied")
"""

from dataclasses import dataclass, field
from typing import Any, Optional, Callable, Dict, List
from enum import Enum
from datetime import datetime
import re
import traceback


class FixAction(Enum):
    """Classification of how to handle a failure."""

    AUTO_FIX = "auto_fix"      # Safe to fix automatically
    SUGGEST = "suggest"        # Provide suggestion, user decides
    MANUAL = "manual"          # Requires manual investigation
    RETRY = "retry"            # Transient error, retry with backoff
    SKIP = "skip"              # Not fixable, skip


@dataclass
class ValidationResult:
    """
    Standard result format from test validation.

    This is what tests return when they complete.
    """

    test_name: str
    test_module: str
    status: str  # "PASS", "FAIL", "ERROR", "SKIP"

    # Validation details
    expected: Optional[Any] = None
    actual: Optional[Any] = None

    # Error info (if failed)
    error: Optional[Exception] = None
    error_message: Optional[str] = None
    error_traceback: Optional[str] = None
    fix_suggestion: Optional[str] = None

    # Timing
    execution_time_ms: float = 0.0
    timestamp: datetime = field(default_factory=datetime.utcnow)

    # Context
    context: Dict[str, Any] = field(default_factory=dict)

    def is_passed(self) -> bool:
        return self.status == "PASS"

    def is_failed(self) -> bool:
        return self.status in ("FAIL", "ERROR")


@dataclass
class FailureAnalysis:
    """
    Analysis of a test failure with correction suggestions.

    Generated by SelfCorrector.analyze_failure().
    """

    test_name: str
    test_module: str
    error_type: str
    error_message: str

    # Root cause analysis
    likely_cause: str
    affected_files: List[str]

    # Correction
    fix_action: FixAction
    fix_description: str
    fix_code: Optional[str] = None  # Auto-generated fix code

    # Confidence in the analysis (0.0 to 1.0)
    confidence: float = 0.5

    # Retry info (for RETRY action)
    retry_delay_seconds: float = 1.0
    max_retries: int = 3

    # Additional context
    analysis_notes: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.utcnow)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "test_name": self.test_name,
            "test_module": self.test_module,
            "error_type": self.error_type,
            "error_message": self.error_message,
            "likely_cause": self.likely_cause,
            "affected_files": self.affected_files,
            "fix_action": self.fix_action.value,
            "fix_description": self.fix_description,
            "fix_code": self.fix_code,
            "confidence": self.confidence,
            "analysis_notes": self.analysis_notes,
            "timestamp": self.timestamp.isoformat(),
        }


class SelfCorrector:
    """
    Analyzes test failures and suggests/applies corrections.

    Error Pattern Handlers:
    - AttributeError: Missing field on model
    - TypeError: Type mismatch (cast/convert)
    - ValidationError: Data validation failure
    - AssertionError: Expected != actual
    - IntegrityError: Database constraint violation
    - KeyError: Missing dictionary key
    - ImportError: Missing import/module
    - TimeoutError: Operation timeout (retry)
    - ConnectionError: Network/DB connection (retry)

    Confidence Thresholds:
    - >= 0.9: Safe for auto-fix
    - >= 0.7: Strong suggestion
    - >= 0.5: Moderate confidence
    - < 0.5: Manual investigation needed
    """

    # Minimum confidence for auto-fix
    AUTO_FIX_THRESHOLD = 0.9

    def __init__(self):
        """Initialize the corrector with error handlers."""
        self.error_handlers: Dict[str, Callable] = {
            "AttributeError": self._handle_attribute_error,
            "TypeError": self._handle_type_error,
            "ValidationError": self._handle_validation_error,
            "AssertionError": self._handle_assertion_error,
            "IntegrityError": self._handle_integrity_error,
            "KeyError": self._handle_key_error,
            "ImportError": self._handle_import_error,
            "ModuleNotFoundError": self._handle_import_error,
            "TimeoutError": self._handle_timeout_error,
            "ConnectionError": self._handle_connection_error,
            "OperationalError": self._handle_connection_error,
        }

        # Track applied fixes for learning
        self.fix_history: List[Dict[str, Any]] = []

    def analyze_failure(self, result: ValidationResult) -> FailureAnalysis:
        """
        Analyze a test failure and determine appropriate fix.

        Args:
            result: ValidationResult from a failed test

        Returns:
            FailureAnalysis with fix suggestion
        """
        if result.is_passed():
            raise ValueError("Cannot analyze a passing test")

        # Determine error type
        if result.error:
            error_type = type(result.error).__name__
        else:
            error_type = "UnknownError"

        # Get appropriate handler
        handler = self.error_handlers.get(error_type, self._handle_unknown_error)

        return handler(result, error_type)

    def apply_fix(self, analysis: FailureAnalysis) -> bool:
        """
        Apply an automatic fix if confidence is high enough.

        Args:
            analysis: FailureAnalysis from analyze_failure()

        Returns:
            True if fix was applied successfully
        """
        # Only auto-fix if action is AUTO_FIX
        if analysis.fix_action != FixAction.AUTO_FIX:
            return False

        # Require high confidence
        if analysis.confidence < self.AUTO_FIX_THRESHOLD:
            return False

        # Require fix code
        if not analysis.fix_code:
            return False

        try:
            # Log the fix attempt
            fix_record = {
                "test_name": analysis.test_name,
                "error_type": analysis.error_type,
                "fix_action": analysis.fix_action.value,
                "confidence": analysis.confidence,
                "timestamp": datetime.utcnow().isoformat(),
                "status": "attempted",
            }

            # TODO: Implement actual fix application
            # This would involve:
            # 1. Parsing the fix_code
            # 2. Identifying the target file
            # 3. Making the modification
            # 4. Validating the syntax

            # For now, record as "suggested" rather than "applied"
            fix_record["status"] = "suggested"
            self.fix_history.append(fix_record)

            return False  # Return False until actual implementation

        except Exception as e:
            # Log failure
            self.fix_history.append({
                "test_name": analysis.test_name,
                "error_type": analysis.error_type,
                "status": "failed",
                "failure_reason": str(e),
                "timestamp": datetime.utcnow().isoformat(),
            })
            return False

    def _handle_attribute_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """
        Handle AttributeError - usually means missing field on model.

        Pattern: "'ClassName' object has no attribute 'field_name'"
        Fix: Add field to model with appropriate type
        """
        error_msg = result.error_message or str(result.error) or ""

        # Extract field name from error
        match = re.search(r"has no attribute '(\w+)'", error_msg)
        field_name = match.group(1) if match else "unknown_field"

        # Extract class name
        class_match = re.search(r"'(\w+)' object", error_msg)
        class_name = class_match.group(1) if class_match else "Model"

        # Infer file path from class name
        model_file = self._infer_model_file(class_name)

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=f"Model '{class_name}' is missing field '{field_name}'",
            affected_files=[model_file] if model_file else ["backend/app/models/*.py"],
            fix_action=FixAction.SUGGEST,
            fix_description=f"Add '{field_name}' field to {class_name} model",
            fix_code=f"""
# Add to {class_name} class in {model_file or 'appropriate model file'}:
{field_name} = Column(String(255))  # Adjust type as needed

# If JSON type:
# {field_name} = Column(JSON, default=dict)

# If Boolean:
# {field_name} = Column(Boolean, default=False)
""".strip(),
            confidence=0.8,
            analysis_notes=[
                f"Missing attribute: {field_name}",
                f"Affected class: {class_name}",
                "Check if field should be nullable or have a default",
            ],
        )

    def _handle_type_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """
        Handle TypeError - type mismatch, wrong arguments, etc.

        Common patterns:
        - "expected X, got Y"
        - "missing required argument"
        - "takes N arguments but M were given"
        """
        error_msg = result.error_message or str(result.error) or ""

        # Detect pattern
        if "missing" in error_msg.lower() and "argument" in error_msg.lower():
            return self._handle_missing_argument(result, error_type, error_msg)
        elif "expected" in error_msg.lower() and "got" in error_msg.lower():
            return self._handle_type_mismatch(result, error_type, error_msg)
        else:
            return self._handle_generic_type_error(result, error_type, error_msg)

    def _handle_missing_argument(
        self,
        result: ValidationResult,
        error_type: str,
        error_msg: str
    ) -> FailureAnalysis:
        """Handle missing required argument."""
        match = re.search(r"missing \d+ required.*argument.*['\"](\w+)['\"]", error_msg)
        arg_name = match.group(1) if match else "argument"

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=f"Function call missing required argument: '{arg_name}'",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.SUGGEST,
            fix_description=f"Add '{arg_name}' argument to function call",
            fix_code=f"""
# Option 1: Add the missing argument
function_call(..., {arg_name}=value)

# Option 2: Make argument optional in function definition
def function_name(..., {arg_name}=None):
""".strip(),
            confidence=0.7,
        )

    def _handle_type_mismatch(
        self,
        result: ValidationResult,
        error_type: str,
        error_msg: str
    ) -> FailureAnalysis:
        """Handle type mismatch (expected X, got Y)."""
        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause="Type mismatch between expected and actual value",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.SUGGEST,
            fix_description="Cast value to correct type or fix data source",
            fix_code="""
# Common type conversions:
str(value)         # Convert to string
int(value)         # Convert to integer
float(value)       # Convert to float
bool(value)        # Convert to boolean
list(value)        # Convert to list
dict(value)        # Convert to dict
json.loads(value)  # Parse JSON string
""".strip(),
            confidence=0.6,
        )

    def _handle_generic_type_error(
        self,
        result: ValidationResult,
        error_type: str,
        error_msg: str
    ) -> FailureAnalysis:
        """Handle generic TypeError."""
        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause="Type-related error in function call or operation",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.MANUAL,
            fix_description="Review the types involved in the operation",
            confidence=0.4,
        )

    def _handle_validation_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """
        Handle ValidationError - data doesn't meet constraints.

        Common in Pydantic models or custom validators.
        """
        error_msg = result.error_message or str(result.error) or ""

        # Try to extract field name
        match = re.search(r"field['\s]+['\"]?(\w+)['\"]?", error_msg, re.IGNORECASE)
        field_name = match.group(1) if match else "unknown"

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=f"Validation failed for field '{field_name}'",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.SUGGEST,
            fix_description="Fix the data to pass validation or update validation rules",
            fix_code=f"""
# Option 1: Fix the data
data["{field_name}"] = valid_value

# Option 2: Make field optional
{field_name}: Optional[str] = None

# Option 3: Add default
{field_name}: str = Field(default="")
""".strip(),
            confidence=0.6,
            analysis_notes=[
                f"Validation failed for: {field_name}",
                "Check the validation rules in the model",
                "Verify the input data meets requirements",
            ],
        )

    def _handle_assertion_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """
        Handle AssertionError - expected != actual.

        Analyze the difference to suggest a fix.
        """
        error_msg = result.error_message or str(result.error) or ""

        # Build detailed description
        fix_desc = "Expected value doesn't match actual value.\n\n"

        if result.expected is not None:
            fix_desc += f"Expected: {result.expected}\n"
        if result.actual is not None:
            fix_desc += f"Actual:   {result.actual}\n"

        fix_desc += "\nReview the implementation logic in the affected files."

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause="Implementation doesn't match specification",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.MANUAL,
            fix_description=fix_desc.strip(),
            fix_code=None,
            confidence=0.5,
            analysis_notes=[
                "This is a logic error requiring manual review",
                "Check the implementation against requirements",
                "Verify test expectations are correct",
            ],
        )

    def _handle_integrity_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """
        Handle IntegrityError - database constraint violation.

        Common causes:
        - Unique constraint violation
        - Foreign key constraint
        - NOT NULL constraint
        """
        error_msg = result.error_message or str(result.error) or ""

        # Detect constraint type
        if "unique" in error_msg.lower() or "duplicate" in error_msg.lower():
            cause = "Duplicate value violates unique constraint"
            fix = "Use unique value or update existing record"
        elif "foreign key" in error_msg.lower():
            cause = "Foreign key references non-existent record"
            fix = "Create referenced record first or use valid FK"
        elif "not null" in error_msg.lower() or "notnull" in error_msg.lower():
            cause = "NULL value for non-nullable column"
            fix = "Provide a value or make column nullable"
        else:
            cause = "Database constraint violation"
            fix = "Check constraint requirements"

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=cause,
            affected_files=["backend/app/models/*.py", "backend/tests/conftest.py"],
            fix_action=FixAction.SUGGEST,
            fix_description=fix,
            fix_code="""
# For unique constraint:
# Use uuid or timestamp to ensure uniqueness
id = str(uuid.uuid4())

# For foreign key:
# Create parent record first
parent = ParentModel(...)
session.add(parent)
await session.flush()  # Get the ID
child = ChildModel(parent_id=parent.id)

# For NOT NULL:
# Either provide value or make nullable
field = Column(String(255), nullable=True)  # Allow NULL
""".strip(),
            confidence=0.7,
        )

    def _handle_key_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """Handle KeyError - missing dictionary/object key."""
        error_msg = result.error_message or str(result.error) or ""

        # Extract key name
        match = re.search(r"['\"](\w+)['\"]", error_msg)
        key_name = match.group(1) if match else "unknown_key"

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=f"Dictionary/object missing key: '{key_name}'",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.SUGGEST,
            fix_description=f"Add '{key_name}' to the data structure or use .get()",
            fix_code=f"""
# Option 1: Use .get() with default
value = data.get("{key_name}", default_value)

# Option 2: Check key exists
if "{key_name}" in data:
    value = data["{key_name}"]

# Option 3: Add the key
data["{key_name}"] = value
""".strip(),
            confidence=0.8,
        )

    def _handle_import_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """Handle ImportError/ModuleNotFoundError."""
        error_msg = result.error_message or str(result.error) or ""

        # Extract module name
        match = re.search(r"No module named ['\"]?([\w.]+)['\"]?", error_msg)
        module_name = match.group(1) if match else "unknown_module"

        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=error_msg,
            likely_cause=f"Module '{module_name}' not found",
            affected_files=["requirements.txt", "pyproject.toml"],
            fix_action=FixAction.SUGGEST,
            fix_description=f"Install missing module: {module_name}",
            fix_code=f"""
# Install the package:
pip install {module_name}

# Or add to requirements.txt:
{module_name}>=0.1.0

# If it's a local module, check PYTHONPATH or __init__.py
""".strip(),
            confidence=0.9,
        )

    def _handle_timeout_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """Handle TimeoutError - operation took too long."""
        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=result.error_message or str(result.error) or "",
            likely_cause="Operation timed out - may be transient",
            affected_files=[],
            fix_action=FixAction.RETRY,
            fix_description="Retry with exponential backoff",
            confidence=0.7,
            retry_delay_seconds=2.0,
            max_retries=3,
            analysis_notes=[
                "This may be a transient issue",
                "Consider increasing timeout for this test",
                "Check if external service is slow",
            ],
        )

    def _handle_connection_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """Handle ConnectionError/OperationalError - network/DB issues."""
        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=result.error_message or str(result.error) or "",
            likely_cause="Connection failed - database or external service unavailable",
            affected_files=["backend/app/database.py", "backend/app/config.py"],
            fix_action=FixAction.RETRY,
            fix_description="Check connection settings and retry",
            confidence=0.6,
            retry_delay_seconds=5.0,
            max_retries=3,
            analysis_notes=[
                "Check DATABASE_URL in config",
                "Verify database/service is running",
                "Check network connectivity",
            ],
        )

    def _handle_unknown_error(
        self,
        result: ValidationResult,
        error_type: str
    ) -> FailureAnalysis:
        """Handle unknown/unexpected errors."""
        return FailureAnalysis(
            test_name=result.test_name,
            test_module=result.test_module,
            error_type=error_type,
            error_message=result.error_message or str(result.error) or "",
            likely_cause=f"Unknown error of type: {error_type}",
            affected_files=self._infer_affected_files(result),
            fix_action=FixAction.MANUAL,
            fix_description="Manual investigation required",
            confidence=0.2,
            analysis_notes=[
                "This error type is not in the known patterns",
                "Check the full traceback for clues",
                "Consider adding a handler for this error type",
            ],
        )

    def _infer_model_file(self, class_name: str) -> Optional[str]:
        """
        Infer the model file path from class name.

        Maps class names to their likely file locations.
        """
        # Model name patterns
        patterns = {
            "Intel": "backend/app/models/intelligence.py",
            "Snapshot": "backend/app/models/versioning.py",
            "Change": "backend/app/models/versioning.py",
            "Alert": "backend/app/models/alerts.py",
            "User": "backend/app/models/platform.py",
            "Team": "backend/app/models/platform.py",
            "Territory": "backend/app/models/platform.py",
            "API": "backend/app/models/platform.py",
            "Audit": "backend/app/models/platform.py",
            "Company": "backend/app/models/core.py",
            "Technology": "backend/app/models/core.py",
            "Displacement": "backend/app/models/targets.py",
            "Competitive": "backend/app/models/targets.py",
            "CaseStudy": "backend/app/models/evidence.py",
            "Quote": "backend/app/models/evidence.py",
            "Proof": "backend/app/models/evidence.py",
            "Enrichment": "backend/app/models/enrichment.py",
        }

        for pattern, file_path in patterns.items():
            if pattern in class_name:
                return file_path

        return None

    def _infer_affected_files(self, result: ValidationResult) -> List[str]:
        """
        Infer which files might be affected from test module.

        Uses test naming conventions:
        - test_models/test_X.py -> models/X.py
        - test_services/test_Y.py -> services/Y.py
        """
        affected = []

        test_module = result.test_module

        if "models" in test_module:
            affected.append("backend/app/models/")
        if "services" in test_module:
            affected.append("backend/app/services/")
        if "api" in test_module or "endpoints" in test_module:
            affected.append("backend/app/api/")
        if "versioning" in test_module:
            affected.append("backend/app/models/versioning.py")
        if "alerts" in test_module:
            affected.append("backend/app/models/alerts.py")

        # Also include the test file itself
        if test_module:
            test_file = f"backend/tests/{test_module.replace('.', '/')}.py"
            affected.append(test_file)

        return affected if affected else ["backend/"]

    def get_summary(self) -> Dict[str, Any]:
        """Get summary of correction activity."""
        total = len(self.fix_history)

        if total == 0:
            return {
                "total_analyzed": 0,
                "auto_fixed": 0,
                "suggested": 0,
                "failed": 0,
            }

        by_status = {}
        for fix in self.fix_history:
            status = fix.get("status", "unknown")
            by_status[status] = by_status.get(status, 0) + 1

        return {
            "total_analyzed": total,
            "auto_fixed": by_status.get("applied", 0),
            "suggested": by_status.get("suggested", 0),
            "failed": by_status.get("failed", 0),
            "by_error_type": self._count_by_field("error_type"),
        }

    def _count_by_field(self, field: str) -> Dict[str, int]:
        """Count fix history by a specific field."""
        counts = {}
        for fix in self.fix_history:
            value = fix.get(field, "unknown")
            counts[value] = counts.get(value, 0) + 1
        return counts
